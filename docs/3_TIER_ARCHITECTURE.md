# PayPerPlay 3-Tier Architecture
**True Pay-Per-Use: Von 70‚Ç¨/Monat Fixkosten zu 7‚Ç¨/Monat Baseline**

**Status:** Planned Architecture
**Current:** Monolith (All-in-One Dedicated Server)
**Target:** 3-Tier Microservices (Control + Proxy + Workload)
**Date:** 2025-11-11

---

## Problem mit der aktuellen Architektur

### Aktueller Zustand: Monolith
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ HETZNER DEDICATED SERVER (91.98.202.235)                ‚îÇ
‚îÇ 70‚Ç¨/month - ALWAYS ON                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  API (Go) + PostgreSQL + Velocity + MC-Server ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  Alles in einem Container/Server              ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  PROBLEME:                                              ‚îÇ
‚îÇ  ‚ùå Website-Traffic blockiert Spieler-Traffic           ‚îÇ
‚îÇ  ‚ùå MC-Server k√∂nnen nicht unabh√§ngig skalieren         ‚îÇ
‚îÇ  ‚ùå Velocity restart = gesamtes System offline          ‚îÇ
‚îÇ  ‚ùå 70‚Ç¨/month Fixkosten auch bei 0 Spielern             ‚îÇ
‚îÇ  ‚ùå Nicht skalierbar √ºber einen Server hinaus           ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Kosten bei 0 Last: 70‚Ç¨/month ‚ùå
Kosten bei Peak Last: 70‚Ç¨/month ‚ùå
Skalierbarkeit: KEINE ‚ùå
```

### PayPerPlay Business Model ‚â† Always-On Server

**PayPerPlay Prinzip:**
- Spieler zahlen nur f√ºr aktive Spielzeit
- Server stoppen bei Inaktivit√§t
- **0 Spieler = 0 Kosten** (f√ºr Spieler)

**Aktuelles System:**
- **0 Spieler = 70‚Ç¨ Fixkosten** (f√ºr uns!)
- Wir zahlen 24/7 f√ºr ungenutzte Kapazit√§t
- Unprofitabel bei niedriger Auslastung

---

## L√∂sung: 3-Tier Architektur

### Architektur-√úbersicht

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TIER 1: CONTROL PLANE (Always-On, Minimal)             ‚îÇ
‚îÇ Hetzner Cloud CX11: 2GB RAM, 1 vCPU                    ‚îÇ
‚îÇ Kosten: 3.50‚Ç¨/month (24/7)                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ API Server (Go Binary)                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - REST API f√ºr Dashboard/Mobile App            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - User Management, Authentication               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Billing & Payment Processing                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Orchestrierung (Conductor)                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  RAM: ~50-100 MB                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ PostgreSQL (Container)                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - User-Daten, Server-Konfiguration             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Billing History, Analytics                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  RAM: ~200-400 MB                                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Dashboard/Website (Nginx + Static Files)        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Frontend (React/Vue)                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Admin Panel                                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  RAM: ~50 MB                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Funktion: Orchestrierung, Verwaltung, Abrechnung      ‚îÇ
‚îÇ  Traffic: NIEDRIG (nur API calls, keine Spieler)       ‚îÇ
‚îÇ  Ports: 8000 (API), 80/443 (Website)                   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TIER 2: PROXY LAYER (Always-On, Isolated)              ‚îÇ
‚îÇ Hetzner Cloud CX11: 2GB RAM, 1 vCPU                    ‚îÇ
‚îÇ Kosten: 3.50‚Ç¨/month (24/7)                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Velocity Proxy (Minecraft BungeeCord)            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Spieler-Routing zu Backend MC-Servern        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Single Entry Point f√ºr alle Spieler          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Hot-Reload von Server-Liste                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  RAM: ~500-800 MB (je nach Spielerzahl)         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Funktion: Spieler-Routing, Load Balancing             ‚îÇ
‚îÇ  Traffic: HOCH (alle Minecraft-Verbindungen)           ‚îÇ
‚îÇ  Port: 25565 (Minecraft Default)                       ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  WARUM ISOLIERT?                                        ‚îÇ
‚îÇ  ‚úì Website-Traffic kollidiert NICHT mit Spielern       ‚îÇ
‚îÇ  ‚úì API restart beeinflusst Spieler NICHT               ‚îÇ
‚îÇ  ‚úì Unabh√§ngiges Monitoring/Scaling                     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TIER 3: WORKLOAD LAYER (100% On-Demand)                ‚îÇ
‚îÇ Hetzner Cloud VMs: Dynamic Scaling                     ‚îÇ
‚îÇ Kosten: 0‚Ç¨ bei 0 Last, X‚Ç¨ bei aktiver Nutzung          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ MC-Server  ‚îÇ  ‚îÇ MC-Server  ‚îÇ  ‚îÇ MC-Server  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ (CX21)     ‚îÇ  ‚îÇ (CX31)     ‚îÇ  ‚îÇ (CX31)     ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ 4GB RAM    ‚îÇ  ‚îÇ 8GB RAM    ‚îÇ  ‚îÇ 8GB RAM    ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Funktion: Minecraft Server Execution                   ‚îÇ
‚îÇ  Lifecycle:                                             ‚îÇ
‚îÇ    1. START: Bei erstem Spieler-Connect                 ‚îÇ
‚îÇ    2. RUN: Solange Spieler online                       ‚îÇ
‚îÇ    3. STOP: Nach 5 Min Idle (keine Spieler)             ‚îÇ
‚îÇ    4. DESTROY: VM wird dekommissioniert                 ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Kommunikation:                                         ‚îÇ
‚îÇ    - Registrierung bei Velocity (via Control Plane)     ‚îÇ
‚îÇ    - Health Checks an Control Plane                     ‚îÇ
‚îÇ    - Metrics/Logs an Monitoring                         ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Kosten: PAY-PER-USE                                    ‚îÇ
‚îÇ    - 0‚Ç¨ wenn keine Server laufen                        ‚îÇ
‚îÇ    - 0.01‚Ç¨/h pro CX21 (2 vCPU, 4GB)                     ‚îÇ
‚îÇ    - 0.02‚Ç¨/h pro CX31 (2 vCPU, 8GB)                     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Warum diese Trennung?

### Separation of Concerns

#### 1. Traffic-Isolation

**Problem (Monolith):**
```
Website-Request ‚Üí Server (√ºberlastet) ‚Üí Langsame MC-Spieler
MC-Spieler ‚Üí Server (√ºberlastet) ‚Üí Langsames Dashboard
```

**L√∂sung (3-Tier):**
```
Website-Request ‚Üí Tier 1 (API) ‚úì Unabh√§ngig
MC-Spieler ‚Üí Tier 2 (Velocity) ‚úì Isoliert
MC-Server ‚Üí Tier 3 (VMs) ‚úì Skaliert automatisch
```

#### 2. Unabh√§ngige Skalierung

**Tier 1 (Control Plane):**
- Ben√∂tigt KEINE Skalierung (1 CX11 reicht f√ºr 10.000+ User)
- API ist stateless (Go binary, sehr effizient)
- PostgreSQL-Load minimal (nur Writes bei User-Aktionen)

**Tier 2 (Proxy):**
- Skaliert bei >1000 gleichzeitigen Spielern (erst nach Monaten!)
- Horizontal skalierbar (mehrere Velocity-Instanzen)
- Single Point of Entry (DNS Load Balancing)

**Tier 3 (Workload):**
- Skaliert bei jedem neuen MC-Server (jetzt!)
- 100% automatisch via ScalingEngine
- Unbegrenzt skalierbar (Hetzner Cloud hat 1000+ VMs)

#### 3. Kosten-Optimierung

**Aktuell:**
```
70‚Ç¨/month egal wie viel genutzt wird
```

**Mit 3-Tier:**
```
Tier 1: 3.50‚Ç¨/month (immer)
Tier 2: 3.50‚Ç¨/month (immer)
Tier 3: 0‚Ç¨ bei 0 Last, ~10-50‚Ç¨ bei Peaks

Total: 7-57‚Ç¨/month (je nach Nutzung)
Durchschnitt: ~15-20‚Ç¨/month
Einsparung: 50-55‚Ç¨/month (71-78%)
```

#### 4. Ausfallsicherheit

**Monolith:**
```
API crash ‚Üí Alles offline ‚ùå
Velocity crash ‚Üí Alles offline ‚ùå
MC-Server bug ‚Üí Potenziell alles offline ‚ùå
```

**3-Tier:**
```
API crash ‚Üí Dashboard offline, aber Spieler spielen weiter ‚úì
Velocity crash ‚Üí MC-Server laufen, werden neu registriert ‚úì
MC-Server bug ‚Üí Nur dieser Server betroffen, Rest l√§uft ‚úì
```

---

## Technische Details

### Tier 1: Control Plane

#### Komponenten

**API Server (Go)**
```go
// Hauptfunktionen:
- User Authentication & Authorization (JWT)
- Server CRUD Operations (Create, Read, Update, Delete)
- Billing & Payment Integration (Stripe/PayPal)
- Conductor Orchestration (VM Management)
- ScalingEngine Control (Auto-Scaling)
- Health Monitoring (alle Tiers)

// Ressourcen:
RAM: 50-100 MB (Go ist sehr effizient)
CPU: <5% bei normalem Traffic
Disk: 500 MB (Binary + Logs)
```

**PostgreSQL**
```sql
-- Schema:
- users (accounts, auth)
- servers (minecraft server configs)
- billing (transactions, usage tracking)
- nodes (fleet management)
- events (audit log, analytics)

-- Ressourcen:
RAM: 200-400 MB (klein, wenige Writes)
CPU: <5% (keine komplexen Queries)
Disk: 5-10 GB (Datenbank + Backups)
```

**Nginx + Frontend**
```nginx
# Static Files:
- React/Vue Dashboard (~10 MB)
- Admin Panel (~5 MB)
- Assets (images, fonts)

# Ressourcen:
RAM: 50 MB (Nginx ist minimal)
CPU: <1%
Disk: 100 MB
```

**Gesamt:**
```
RAM: ~300-550 MB (von 2048 MB = 15-27% genutzt)
CPU: <10% durchschnittlich
Reserve: 1.5 GB RAM frei f√ºr Peaks
```

#### Netzwerk-Konfiguration

```yaml
# docker-compose.control-plane.yml
services:
  api:
    image: payperplay/api:latest
    ports:
      - "8000:8000"  # REST API
    environment:
      - DATABASE_URL=postgresql://postgres:5432/payperplay
      - VELOCITY_API_URL=http://velocity-vm:8080
      - HETZNER_CLOUD_TOKEN=${HETZNER_CLOUD_TOKEN}
    networks:
      - control-net

  postgres:
    image: postgres:16-alpine
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - control-net

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./frontend/dist:/usr/share/nginx/html
    networks:
      - control-net

networks:
  control-net:
    driver: bridge
```

---

### Tier 2: Proxy Layer

#### Velocity Proxy

**Konfiguration:**
```yaml
# velocity.toml
[servers]
try = []  # Dynamisch gef√ºllt via API

[forced-hosts]
"play.payperplay.host" = []  # Alle Server

[advanced]
compression-threshold = 256
compression-level = -1
login-ratelimit = 3000
connection-timeout = 5000
read-timeout = 30000
```

**Remote API f√ºr dynamische Server-Registrierung:**
```go
// Velocity Plugin: VelocityRemoteAPI
// Lauscht auf Port 8080 f√ºr HTTP Requests

// POST /api/servers
// Body: {"name": "survival-1", "address": "10.0.1.5:25566"}
func RegisterServer(w http.ResponseWriter, r *http.Request) {
    var server ServerRegistration
    json.NewDecoder(r.Body).Decode(&server)

    // F√ºge Server zur Velocity-Config hinzu
    proxyServer.getServer(server.Name).ifPresent(s ->
        s.setAddress(server.Address)
    )

    // Reload Velocity Config (kein Restart!)
    proxyServer.reloadConfiguration()
}
```

**Control Plane Integration:**
```go
// internal/velocity/remote_client.go
type RemoteVelocityClient struct {
    apiURL string  // http://velocity-vm:8080
}

func (c *RemoteVelocityClient) RegisterServer(name, address string) error {
    payload := map[string]string{
        "name":    name,
        "address": address,
    }

    resp, err := http.Post(
        c.apiURL + "/api/servers",
        "application/json",
        toJSON(payload),
    )

    return handleResponse(resp, err)
}
```

**Ressourcen:**
```
RAM: 500-800 MB (je nach Spielerzahl)
  - 500 MB base
  - +1 MB pro 10 gleichzeitige Spieler
  - Max 2 GB (bei 1500+ Spielern)

CPU: 10-30% (Packet Forwarding)
Netzwerk: HOCH (alle MC-Traffic)
  - Eingehend: ~1-5 Mbit/s pro Spieler
  - Ausgehend: ~1-5 Mbit/s pro Spieler
```

#### Warum isoliert?

1. **Performance:** API-Traffic beeinflusst MC-Latency NICHT
2. **Skalierung:** Velocity kann unabh√§ngig hochskaliert werden
3. **Monitoring:** Separate Metrics f√ºr API vs. MC-Traffic
4. **Debugging:** Velocity-Logs separat von API-Logs

---

### Tier 3: Workload Layer

#### On-Demand MC-Server

**Provisioning Flow:**
```
1. User klickt "Server starten" im Dashboard
   ‚îî‚îÄ> POST /api/servers/:id/start

2. Control Plane (Conductor) pr√ºft Kapazit√§t
   ‚îî‚îÄ> NodeRegistry.FindBestNode(ramMB)

3a. FALL 1: Node mit Kapazit√§t vorhanden
    ‚îî‚îÄ> StartContainerRemote(node, server)

3b. FALL 2: Keine Kapazit√§t (>85% ausgelastet)
    ‚îî‚îÄ> ScalingEngine.ProvisionNode()
    ‚îî‚îÄ> Hetzner Cloud API: Create VM (CX21/CX31)
    ‚îî‚îÄ> Wait for ready (~2 minutes)
    ‚îî‚îÄ> StartContainerRemote(newNode, server)

4. Container startet auf Remote-VM
   ‚îî‚îÄ> SSH oder Docker API √ºber Netzwerk

5. Server registriert bei Velocity
   ‚îî‚îÄ> POST http://velocity-vm:8080/api/servers
   ‚îî‚îÄ> Body: {name: "survival-1", address: "10.0.1.5:25566"}

6. User kann connecten via play.payperplay.host
   ‚îî‚îÄ> Velocity routet zu 10.0.1.5:25566
```

**Container Management (Remote):**
```go
// internal/conductor/remote_docker.go
type RemoteDockerClient struct {
    sshClient *ssh.Client
}

func (c *RemoteDockerClient) StartContainer(node *Node, server *Server) error {
    // Option 1: Docker API √ºber SSH Tunnel
    dockerCmd := fmt.Sprintf(
        "docker run -d --name mc-%s -p %d:25565 -m %dM %s",
        server.ID,
        server.Port,
        server.RAMMB,
        server.ImageName,
    )

    // SSH Execute
    session, _ := c.sshClient.NewSession()
    defer session.Close()

    output, err := session.CombinedOutput(dockerCmd)

    // Option 2: Docker Remote API (TCP)
    // client := docker.NewClient("tcp://10.0.1.5:2375")
    // client.ContainerCreate(...)

    return err
}
```

**Auto-Stop bei Idle:**
```go
// internal/monitoring/activity_monitor.go
func (m *ActivityMonitor) CheckIdleServers() {
    for _, server := range m.getRunningServers() {
        // Pr√ºfe Spieler-Count via Velocity API
        playerCount := m.velocityClient.GetPlayerCount(server.Name)

        if playerCount == 0 {
            idleTime := time.Since(server.LastActivity)

            if idleTime > 5*time.Minute {
                // Stop Container
                m.conductor.StopServer(server.ID)

                // Unregister von Velocity
                m.velocityClient.UnregisterServer(server.Name)

                // Nach 1h: VM decommissionen (wenn leer)
                if time.Since(server.StoppedAt) > 1*time.Hour {
                    node := m.nodeRegistry.GetNode(server.NodeID)
                    if node.ContainerCount == 0 {
                        m.scalingEngine.DecommissionNode(node.ID)
                    }
                }
            }
        }
    }
}
```

---

## Kosten-Breakdown

### Baseline (0 Last)

```
Tier 1 (Control Plane):  3.50‚Ç¨/month  (CX11, always-on)
Tier 2 (Proxy Layer):    3.50‚Ç¨/month  (CX11, always-on)
Tier 3 (Workload):       0.00‚Ç¨/month  (keine VMs)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL:                   7.00‚Ç¨/month

Einsparung vs. Monolith: 70‚Ç¨ - 7‚Ç¨ = 63‚Ç¨/month (90% g√ºnstiger!)
```

### Normale Auslastung (10 MC-Server, je 4h/Tag)

```
Tier 1: 3.50‚Ç¨/month
Tier 2: 3.50‚Ç¨/month
Tier 3: 10 Server √ó 0.01‚Ç¨/h √ó 4h √ó 30 Tage = 12.00‚Ç¨/month
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL: 19.00‚Ç¨/month

Einsparung vs. Monolith: 70‚Ç¨ - 19‚Ç¨ = 51‚Ç¨/month (73% g√ºnstiger!)
```

### Peak Auslastung (50 MC-Server, je 8h/Tag)

```
Tier 1: 3.50‚Ç¨/month
Tier 2: 3.50‚Ç¨/month (Velocity kann 100+ Server routen)
Tier 3: 50 Server √ó 0.01‚Ç¨/h √ó 8h √ó 30 Tage = 120.00‚Ç¨/month
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL: 127.00‚Ç¨/month

Break-Even Point: Bei ~50 Servern √° 8h/Tag
Bei mehr Last: Monolith w√§re unpraktikabel (nur 1 Server!)
Mit 3-Tier: Unbegrenzt skalierbar
```

### Kosten-Vergleich Tabelle

| Szenario | Monolith | 3-Tier | Einsparung |
|----------|----------|--------|------------|
| 0 Server | 70‚Ç¨ | 7‚Ç¨ | **90%** |
| 5 Server (2h/Tag) | 70‚Ç¨ | 10‚Ç¨ | **86%** |
| 10 Server (4h/Tag) | 70‚Ç¨ | 19‚Ç¨ | **73%** |
| 20 Server (6h/Tag) | 70‚Ç¨ + mehr Hardware! | 43‚Ç¨ | - |
| 50 Server (8h/Tag) | Nicht m√∂glich | 127‚Ç¨ | ‚àû |

**Fazit:** 3-Tier ist bei niedriger bis mittlerer Last **deutlich g√ºnstiger** und bei hoher Last **√ºberhaupt erst m√∂glich**.

---

## Migration Roadmap

### Phase 0: Vorbereitung (Jetzt)

**Status:** ‚úÖ Bereits teilweise fertig!

- ‚úÖ Auto-Scaling Code (85% fertig)
- ‚úÖ NodeRegistry (Fleet Management)
- ‚úÖ Hetzner Cloud Integration
- ‚úÖ VM Provisioning
- ‚ö†Ô∏è Velocity l√§uft noch lokal (auf Monolith)
- ‚ö†Ô∏è MC-Server starten nur lokal

**Aufgaben:**
- [x] Auto-Scaling konfigurieren (Hetzner Token)
- [x] Testing des aktuellen Systems
- [ ] Dokumentation lesen und verstehen

**Zeitaufwand:** 1-2 Tage (Testing)

---

### Phase 1: Velocity auslagern (Tier 2)

**Ziel:** Velocity auf separater VM, Remote-API bauen

**Schritte:**

1. **Velocity-VM erstellen (1 Stunde)**
   ```bash
   hcloud server create \
     --name payperplay-velocity \
     --type cx11 \
     --image ubuntu-22.04 \
     --ssh-key payperplay-main \
     --location nbg1

   # Output: 95.217.xxx.xxx (IP merken!)
   ```

2. **Velocity + Remote API installieren (2 Stunden)**
   ```bash
   ssh root@95.217.xxx.xxx

   # Docker installieren
   curl -fsSL https://get.docker.com | sh

   # Velocity Container starten
   docker run -d \
     --name velocity \
     -p 25565:25577 \
     -p 8080:8080 \
     -v /opt/velocity:/config \
     payperplay/velocity-with-api:latest
   ```

3. **Remote API Plugin entwickeln (1 Tag)**
   ```java
   // VelocityRemoteAPI Plugin
   // POST /api/servers - Server registrieren
   // DELETE /api/servers/:name - Server entfernen
   // GET /api/servers - Alle Server auflisten
   // GET /api/players/:server - Spieler-Count
   ```

4. **Control Plane anpassen (1 Tag)**
   ```go
   // internal/velocity/velocity_service.go

   // Alt: Lokaler Docker-Container
   // func (v *VelocityService) RegisterServer(...)

   // Neu: Remote HTTP API
   type RemoteVelocityClient struct {
       apiURL string
   }

   func NewRemoteVelocityClient(url string) *RemoteVelocityClient {
       return &RemoteVelocityClient{apiURL: url}
   }
   ```

5. **Testing (1 Tag)**
   - MC-Server lokal starten
   - Registrierung bei Remote-Velocity pr√ºfen
   - Spieler-Connect testen
   - Failover-Tests (Velocity Restart)

**Dateien zu √§ndern:**
- `internal/velocity/velocity_service.go` (Remote-Client)
- `pkg/config/config.go` (VELOCITY_API_URL)
- `cmd/api/main.go` (Client initialisieren)

**Zeitaufwand:** 3-4 Tage

**Risiko:** Niedrig (Velocity ist stabil, nur API-Wrapper)

---

### Phase 2: Remote Container Orchestration (Tier 3)

**Ziel:** MC-Server auf Cloud-VMs starten (nicht nur lokal)

**Schritte:**

1. **Remote Docker Client (2 Tage)**
   ```go
   // internal/docker/remote_client.go

   type RemoteDockerClient struct {
       sshConfig *ssh.ClientConfig
   }

   func (c *RemoteDockerClient) StartContainer(node *Node, server *Server) error {
       // SSH Connection zu Remote-Node
       client, _ := ssh.Dial("tcp", node.IPAddress+":22", c.sshConfig)
       defer client.Close()

       // Docker Command ausf√ºhren
       session, _ := client.NewSession()
       cmd := fmt.Sprintf("docker run -d ...")
       output, err := session.CombinedOutput(cmd)

       return err
   }
   ```

2. **Conductor erweitern (1 Tag)**
   ```go
   // internal/conductor/conductor.go

   func (c *Conductor) StartServer(serverID string) error {
       server := c.getServer(serverID)

       // Node finden (lokal ODER remote!)
       node := c.nodeRegistry.FindBestNode(server.RAMMB)

       if node == nil {
           // Keine Kapazit√§t ‚Üí Auto-Scale!
           node = c.scalingEngine.ProvisionNode("cx21")
       }

       // Container starten (Remote!)
       if node.Type == "cloud" {
           c.remoteDocker.StartContainer(node, server)
       } else {
           c.localDocker.StartContainer(server)
       }

       // Bei Velocity registrieren
       address := fmt.Sprintf("%s:%d", node.IPAddress, server.Port)
       c.velocityClient.RegisterServer(server.Name, address)

       return nil
   }
   ```

3. **Cross-VM Networking (1 Tag)**
   ```bash
   # Hetzner Cloud Private Network
   hcloud network create \
     --name payperplay-net \
     --ip-range 10.0.0.0/16

   # Alle VMs in gleiches Network
   hcloud server attach-to-network \
     --network payperplay-net \
     payperplay-velocity
   ```

4. **Testing (2 Tage)**
   - VM-Provisioning testen
   - Container auf Remote-VM starten
   - Velocity-Registrierung pr√ºfen
   - Spieler-Connect √ºber Velocity ‚Üí Remote-VM
   - Auto-Scale testen (>85% Kapazit√§t)
   - Auto-Stop testen (Idle nach 5 Min)

**Dateien zu √§ndern:**
- `internal/docker/remote_client.go` (NEU)
- `internal/conductor/conductor.go` (StartServer erweitern)
- `internal/conductor/scaling_engine.go` (Network-Setup)

**Zeitaufwand:** 5-6 Tage

**Risiko:** Mittel (Networking kann tricky sein)

---

### Phase 3: Tier 1 auf minimal Dedicated (Optional)

**Ziel:** Control Plane auf g√ºnstigstes Setup migrieren

**Option A: Kleinere Hetzner Cloud VM (CX11)**
```
Aktuell: Dedicated AX41 (70‚Ç¨/month)
Neu: Cloud CX11 (3.50‚Ç¨/month)
Einsparung: 66.50‚Ç¨/month
```

**Option B: Hetzner Auction Server**
```
Gebrauchte Server ab 15‚Ç¨/month
Mehr RAM als CX11, aber immer "always-on"
```

**Empfehlung:** Sp√§ter entscheiden (nach Phase 2)

**Zeitaufwand:** 1-2 Tage (Migration + DNS Update)

---

### Phase 4: Monitoring & Observability

**Ziel:** Vollst√§ndige Transparenz √ºber alle 3 Tiers

**Komponenten:**

1. **Prometheus (Metrics)**
   ```yaml
   # Metrics sammeln:
   - payperplay_api_requests_total
   - payperplay_server_starts_total
   - payperplay_fleet_capacity_percent
   - payperplay_velocity_players_online
   - payperplay_cloud_cost_eur_hour
   ```

2. **Grafana (Dashboards)**
   ```
   Dashboard 1: Control Plane Health
   - API Response Time
   - Database Connections
   - Memory Usage

   Dashboard 2: Proxy Layer
   - Velocity Players Online
   - Server Count
   - Network Traffic

   Dashboard 3: Workload Layer
   - MC-Server Count
   - VM Count (Cloud)
   - Auto-Scaling Events
   - Cost per Hour
   ```

3. **Alerting**
   ```yaml
   - Alert: API Down (>5 min)
   - Alert: Velocity Down (>2 min)
   - Alert: Scaling Failed
   - Alert: Cost > 100‚Ç¨/day
   ```

**Zeitaufwand:** 2-3 Tage

---

## Gesamt-Timeline

| Phase | Aufgabe | Zeitaufwand | Priorit√§t |
|-------|---------|-------------|-----------|
| Phase 0 | Auto-Scaling testen | 1-2 Tage | ‚úÖ **JETZT** |
| Phase 1 | Velocity auslagern | 3-4 Tage | üî¥ **HOCH** |
| Phase 2 | Remote Orchestration | 5-6 Tage | üî¥ **HOCH** |
| Phase 3 | Control Plane migrieren | 1-2 Tage | üü° **MITTEL** |
| Phase 4 | Monitoring | 2-3 Tage | üü¢ **NIEDRIG** |

**Gesamt:** 12-17 Arbeitstage (2.5-3.5 Wochen)

**Empfohlene Reihenfolge:**
1. Phase 0 zuerst (Auto-Scaling funktioniert, aber lokal)
2. Phase 1+2 zusammen (Velocity + Remote = 8-10 Tage)
3. Phase 3+4 sp√§ter (wenn System stabil l√§uft)

---

## Risiken & Mitigation

### Risiko 1: Networking-Probleme

**Problem:** VMs k√∂nnen nicht miteinander kommunizieren

**Mitigation:**
- Hetzner Cloud Private Network nutzen (10.0.0.0/16)
- Firewall-Rules testen (SSH, Docker API, Minecraft Ports)
- Fallback: √ñffentliche IPs nutzen (weniger sicher)

### Risiko 2: SSH-Overhead

**Problem:** SSH-Verbindungen f√ºr Docker-Commands langsam

**Mitigation:**
- Docker Remote API √ºber TCP aktivieren (Port 2375)
- Connection Pooling (SSH-Verbindungen wiederverwenden)
- Alternatve: Kubernetes (sp√§ter, wenn wirklich n√∂tig)

### Risiko 3: Velocity Single Point of Failure

**Problem:** Wenn Velocity down ‚Üí Alle Spieler offline

**Mitigation:**
- Health Checks (alle 30s)
- Auto-Restart bei Failure
- Sp√§ter: Mehrere Velocity-Instanzen + DNS Load Balancing

### Risiko 4: Kosten-Explosion

**Problem:** Viele VMs laufen, kosten steigen unkontrolliert

**Mitigation:**
- SCALING_MAX_CLOUD_NODES=10 (Safety Limit)
- Cost Alerts (>50‚Ç¨/Tag ‚Üí Warning)
- Auto-Stop nach Idle (5 Min)
- Decommission leerer VMs (nach 1h)

---

## FAQ

### Q: Warum nicht Kubernetes?

**A:** Kubernetes ist Overkill f√ºr unseren Use-Case:

**Vorteile von Kubernetes:**
- Automatisches Load Balancing ‚úì
- Self-Healing ‚úì
- Declarative Configuration ‚úì

**Nachteile:**
- **Komplexit√§t:** 5-10x mehr Code/Config
- **Kosten:** Mindestens 3 Nodes f√ºr HA (3√ó7‚Ç¨ = 21‚Ç¨ baseline!)
- **Overhead:** Kubernetes Control Plane braucht ~2 GB RAM
- **Lernkurve:** 2-3 Wochen Einarbeitung

**Unsere L√∂sung:**
- Einfacher: Docker + SSH + Hetzner Cloud API
- G√ºnstiger: 7‚Ç¨ baseline statt 21‚Ç¨
- Wartbar: Einfacher zu debuggen
- Sp√§ter migrieren: Wenn wir wirklich >100 VMs haben

### Q: Was passiert bei Velocity-Ausfall?

**A:** Spieler k√∂nnen nicht connecten, aber laufende Server bleiben online.

**Fallback:**
1. Health Check erkennt Ausfall (30s)
2. Auto-Restart von Velocity-Container (10s)
3. Server re-registrieren automatisch (30s)
4. **Gesamt-Downtime: ~1 Minute**

**Sp√§ter:** Hot-Standby Velocity (zweite Instanz)

### Q: K√∂nnen wir sp√§ter auf AWS/GCP migrieren?

**A:** Ja! Die Architektur ist provider-agnostic.

**Was zu √§ndern:**
- `internal/cloud/hetzner_provider.go` ‚Üí `aws_provider.go`
- API Calls anpassen (AWS EC2 statt Hetzner Cloud)
- Networking (VPC statt Hetzner Private Network)

**Was GLEICH bleibt:**
- ScalingEngine-Logik
- Conductor
- API
- Velocity-Integration

### Q: Was ist mit Backups?

**A:** Backups bleiben auf Object Storage (S3-kompatibel).

**Strategie:**
- MC-Server Daten ‚Üí Hetzner Storage Box (5 TB = 3.20‚Ç¨/month)
- PostgreSQL ‚Üí Daily Backup zu Storage Box
- Bei Server-Stop: Automatisches Backup zu Storage
- Bei Server-Start: Restore von Storage

---

## N√§chste Schritte

### Sofort (diese Woche):

1. **Auto-Scaling testen**
   - Hetzner Cloud Token konfigurieren
   - Erste VM provisionieren
   - Logs beobachten

2. **Dokumentation lesen**
   - `docs/SCALING_ARCHITECTURE.md`
   - `docs/AUTO_SCALING_QUICK_START.md`
   - Dieses Dokument (`3_TIER_ARCHITECTURE.md`)

### N√§chste 2 Wochen:

3. **Phase 1: Velocity auslagern**
   - VM erstellen
   - Remote API entwickeln
   - Control Plane anpassen
   - Testing

### N√§chste 4 Wochen:

4. **Phase 2: Remote Orchestration**
   - Remote Docker Client
   - Conductor erweitern
   - Testing
   - Produktiv-Deployment

---

## Zusammenfassung

### Aktuelle Situation
- ‚ùå Monolith: Alles auf einem Server (70‚Ç¨/month)
- ‚ùå Nicht skalierbar
- ‚ùå Unprofitabel bei niedriger Last

### Ziel-Architektur
- ‚úÖ 3 Tiers: Control + Proxy + Workload
- ‚úÖ Vollst√§ndig skalierbar (0 bis ‚àû Server)
- ‚úÖ 7‚Ç¨/month bei 0 Last (90% g√ºnstiger!)
- ‚úÖ Pay-per-use f√ºr MC-Server

### Aufwand
- **Phase 1+2:** 8-10 Arbeitstage (Velocity + Remote)
- **Gesamt:** 12-17 Arbeitstage (mit Monitoring)
- **Empfehlung:** Schritt f√ºr Schritt, jede Phase testen

### ROI (Return on Investment)
```
Entwicklungszeit: ~3 Wochen
Kosten-Einsparung: ~50-60‚Ç¨/month
Break-Even: Nach 1 Monat! üéâ

Jahr 1: 600-700‚Ç¨ gespart
Jahr 2: Unbezahlbar (Skalierbarkeit!)
```

---

**Fragen?** Siehe `docs/AUTO_SCALING_QUICK_START.md` f√ºr erste Schritte!
